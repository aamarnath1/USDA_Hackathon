{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73c77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing our Packages\n",
    "#If anything doesn't work, use !pip install package_name\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datasets\n",
    "import requests\n",
    "import re\n",
    "#package name is pillow\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "#package name is \"segments-ai\"\n",
    "from segments import SegmentsClient, SegmentsDataset\n",
    "from segments.utils import export_dataset, load_label_bitmap_from_url, get_semantic_bitmap\n",
    "from segments.huggingface import release2dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66efa714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning?\n",
    "\n",
    "input_directory = os.getcwd() + '/data/Path2/Path2-Model Training/Path2 Training Images'\n",
    "output_directory = os.getcwd() + '/data/Path2/Path2-Model Training/Training-PNG'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the directory\n",
    "all_files = os.listdir(input_directory)\n",
    "all_files\n",
    "\n",
    "# Filter for .tif files\n",
    "tif_files = [file for file in all_files if file.endswith('.tif')]\n",
    "\n",
    "for tif_file in tif_files:\n",
    "    # Construct the full file path\n",
    "    full_path = os.path.join(input_directory, tif_file)\n",
    "    \n",
    "    with Image.open(full_path) as img:\n",
    "\n",
    "        base_name = os.path.splitext(tif_file)[0]\n",
    "        output_path_png = os.path.join(output_directory, f'{base_name}.png')\n",
    "        img.save(output_path_png, 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e234afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Preloading all samples. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 40/40 [00:00<00:00, 298.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 40 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading Data from Segments.ai\n",
    "#!pip install --upgrade segments-ai\n",
    "\n",
    "\n",
    "api_key = \"7b8fe6e8c2ee6ebfc9a2df2a4397ab7d80375620\" #API KEY\n",
    "client = SegmentsClient(api_key)\n",
    "\n",
    "#datasets = client.get_datasets()\n",
    "#print(datasets)\n",
    "\n",
    "dataset_identifier = 'aamarnath1/USDA_Hackathon-clone'\n",
    "name = 'v1.0'\n",
    "release = client.get_release(dataset_identifier, name)\n",
    "dataset = SegmentsDataset(release, labelset='ground-truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6c5850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uuid='0f3f61c9-8bd0-4e1f-bea7-912070f7728e' name='v1.0' description='labelled' release_type='JSON' attributes=URL(url='https://segmentsai-prod.s3.amazonaws.com/releases/0f3f61c9-8bd0-4e1f-bea7-912070f7728e.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA5RYRXRX2XBW5X4DZ%2F20240406%2Feu-west-2%2Fs3%2Faws4_request&X-Amz-Date=20240406T193647Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=f85bb128dbc87063f0a02491e634ac5db3f2fc29ed5513d5cf1a19b5908e39e4') status='SUCCEEDED' created_at='2024-04-06T04:55:36.849670Z' samples_count=40\n"
     ]
    }
   ],
   "source": [
    "print(release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9deff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<segments.dataset.SegmentsDataset object at 0x00000244DE2FBDF0>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67c8a0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a21f7251114631ae6b2e7622b2fa0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e6a92481284b40bc55cd8997612a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hfdataset = release2dataset(release, download_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbad8d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2433c1d94d954f98848043590b4f736c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Need to convert bitmaps into semantic bitmaps\n",
    "\n",
    "def convert_segmentation_bitmap(example):\n",
    "    return {\n",
    "        \"label.segmentation_bitmap\":\n",
    "            get_semantic_bitmap(\n",
    "                example[\"label.segmentation_bitmap\"],\n",
    "                example[\"label.annotations\"],\n",
    "            )\n",
    "    }\n",
    "\n",
    "\n",
    "semantic_dataset = hfdataset.map(\n",
    "    convert_segmentation_bitmap,\n",
    ")\n",
    "\n",
    "semantic_dataset = semantic_dataset.rename_column('image', 'pixel_values')\n",
    "semantic_dataset = semantic_dataset.rename_column('label.segmentation_bitmap', 'label.bitmap')\n",
    "semantic_dataset = semantic_dataset.remove_columns(['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "057fe601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': Value(dtype='string', id=None),\n",
       " 'uuid': Value(dtype='string', id=None),\n",
       " 'status': Value(dtype='string', id=None),\n",
       " 'image': Image(decode=True, id=None),\n",
       " 'label.annotations': [{'id': Value(dtype='int32', id=None),\n",
       "   'category_id': Value(dtype='int32', id=None)}],\n",
       " 'label.segmentation_bitmap': Image(decode=True, id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfdataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "554e1e53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': Value(dtype='string', id=None),\n",
       " 'uuid': Value(dtype='string', id=None),\n",
       " 'pixel_values': Image(decode=True, id=None),\n",
       " 'label.annotations': [{'id': Value(dtype='int32', id=None),\n",
       "   'category_id': Value(dtype='int32', id=None)}],\n",
       " 'label.bitmap': Image(decode=True, id=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa4ce308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_bitmap(url):\n",
    "    response = requests.get(url)\n",
    "    bitmap_image = Image.open(BytesIO(response.content)).convert(\"L\")  # Convert to grayscale for simplicity\n",
    "    bitmap_array = np.array(bitmap_image)\n",
    "    return bitmap_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c126243",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bitmap_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbitmap_array\u001b[49m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(bitmap_array)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bitmap_array' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(bitmap_array)\n",
    "plt.imshow(bitmap_array)\n",
    "plt.show()\n",
    "\n",
    "# After obtaining the bitmap array\n",
    "unique_values = np.unique(bitmap_array)\n",
    "print(\"Unique pixel values in the bitmap:\", unique_values)\n",
    "print(bitmap_image.mode)  # Should typically be 'L' for 8-bit pixels, black and white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99aa4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUTTING PIXEL DIMNESIONS FROM BITMAP WITH DATA\n",
    "excel_data = pd.read_excel(os.getcwd() + '/data/Path2/Path2-Model Training/Path2 Data.xlsx')\n",
    "\n",
    "# Function to calculate ribeye area and fat thickness from bitmap\n",
    "def calculate_measurements_from_bitmap(bitmap):\n",
    "    ribeye_pixels = np.sum(bitmap == 1)\n",
    "    fat_thickness_pixels = np.sum(bitmap == 2)\n",
    "    \n",
    "    return ribeye_pixels, fat_thickness_pixels\n",
    "\n",
    "for sample in semantic_dataset:\n",
    "    \n",
    "    filename = sample['name']  # Assuming this is where the filename is stored\n",
    "    match = re.search(r'\\d+', filename)\n",
    "    if match:\n",
    "        carcass_id = int(match.group())\n",
    "    else:\n",
    "        # If no matching numeric part is found, skip this sample or handle it as needed\n",
    "        continue\n",
    "        \n",
    "    # Directly access the bitmap image\n",
    "    bitmap_image = sample['label.bitmap']  # Placeholder for direct access; adjust as needed\n",
    "    \n",
    "    # Assuming bitmap_image is already in a suitable format (numpy array) after your preprocessing steps\n",
    "    bitmap_array = bitmap_image\n",
    "    \n",
    "    # Calculate pixel counts for ribeye area and fat thickness\n",
    "    ribeye_pixels, fat_thickness_pixels = calculate_measurements_from_bitmap(bitmap_array)\n",
    "    \n",
    "    if carcass_id in excel_data['Carcass ID'].values:\n",
    "        excel_data.loc[excel_data['Carcass ID'] == carcass_id, 'Ribeye Area Pixels'] = ribeye_pixels\n",
    "        excel_data.loc[excel_data['Carcass ID'] == carcass_id, 'Fat Thickness Pixels'] = fat_thickness_pixels\n",
    "\n",
    "# After the loop, save the updated DataFrame to an Excel file\n",
    "excel_data.to_excel(os.getcwd() + '/data/Path2/Path2-Model Training/Data-Pixels.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your Excel file into a DataFrame\n",
    "excel_data = pd.read_excel(os.getcwd() + '/data/Path2/Path2-Model Training/Path2 Data.xlsx')\n",
    "\n",
    "# Define your conversion factors (these need to be calibrated for your dataset)\n",
    "pixels_per_square_inch = 0.0001124  # Placeholder value\n",
    "pixels_per_inch = 0.0001124  # Placeholder value\n",
    "\n",
    "\n",
    "# Function to calculate ribeye area and fat thickness from bitmap\n",
    "def calculate_measurements_from_bitmap(bitmap):\n",
    "    ribeye_pixels = np.sum(bitmap == 1)\n",
    "    fat_thickness_pixels = np.sum(bitmap == 2)\n",
    "    \n",
    "    return ribeye_pixels, fat_thickness_pixels\n",
    "\n",
    "# Function to convert pixel measurements to real-world measurements\n",
    "def convert_pixels_to_measurements(ribeye_pixels, fat_thickness_pixels, pixels_per_square_inch, pixels_per_inch):\n",
    "    ribeye_area_sq_in = ribeye_pixels * pixels_per_square_inch\n",
    "    fat_thickness_in = fat_thickness_pixels * pixels_per_inch\n",
    "    \n",
    "    return ribeye_area_sq_in, fat_thickness_in\n",
    "\n",
    "\n",
    "for sample in semantic_dataset:\n",
    "    \n",
    "    filename = sample['name']  # Assuming this is where the filename is stored\n",
    "    match = re.search(r'\\d+', filename)\n",
    "    if match:\n",
    "        carcass_id = int(match.group())\n",
    "    else:\n",
    "        # If no matching numeric part is found, skip this sample or handle it as needed\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    # Directly access the bitmap image; how to do this depends on the dataset object's methods\n",
    "    bitmap_image = sample['label.bitmap']\n",
    "    \n",
    "    # Example conversion from a PIL Image (if applicable)\n",
    "    if isinstance(bitmap_image, Image.Image):\n",
    "        bitmap_array = np.array(bitmap_image)\n",
    "    else:\n",
    "        # If 'bitmap_image' is already a numpy array or similar, you can directly use it\n",
    "        bitmap_array = bitmap_image  # Assuming it's already in the correct format\n",
    "    \n",
    "    # Calculate measurements\n",
    "    ribeye_pixels, fat_thickness_pixels = calculate_measurements_from_bitmap(bitmap_array)\n",
    "    area_sq_in, thickness_in = convert_pixels_to_measurements(ribeye_pixels, fat_thickness_pixels, pixels_per_square_inch, pixels_per_inch)\n",
    "    \n",
    "    # Assuming you can correlate the sample with an Excel row (e.g., via a unique identifier or filename)\n",
    "    # Update the Excel DataFrame (make sure to define and load excel_data DataFrame beforehand)\n",
    "    if carcass_id in excel_data['Carcass ID'].values:\n",
    "        excel_data.loc[excel_data['Carcass ID'] == carcass_id, 'Calculated Ribeye Area (sq in)'] = area_sq_in\n",
    "        excel_data.loc[excel_data['Carcass ID'] == carcass_id, 'Calculated Fat Thickness (in)'] = thickness_in\n",
    "\n",
    "# Save the updated DataFrame back to an Excel file\n",
    "excel_data.to_excel(os.getcwd() + '/data/Path2/Path2-Model Training/UpdatedData.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a888d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d464a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08352653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285cc4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    # Assuming you have a way to identify the URL or direct access to the bitmap\n",
    "    bitmap_url = sample['category_id']['label.bitmap']['url']\n",
    "    bitmap = load_label_bitmap_from_url(bitmap_url)\n",
    "    \n",
    "    # Calculate measurements from the bitmap\n",
    "    ribeye_pixels, fat_thickness_pixels = calculate_measurements_from_bitmap(bitmap)\n",
    "    area_sq_in, thickness_in = convert_pixels_to_measurements(ribeye_pixels, fat_thickness_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your Excel data\n",
    "excel_data = pd.read_excel('/Users/Arya/Documents/Data Science/Spring Hackathon/USDA_Hackathon/data/Path2/Path2-Model Training/Path2 Data.xlsx')  # Adjust the filename as necessary\n",
    "\n",
    "# Assuming 'segmentations' is a list of bitmap arrays corresponding to your Excel rows\n",
    "# This needs to be populated based on how you access your Segment AI dataset\n",
    "segmentations = [...]  # Populate this list with your bitmap data arrays\n",
    "\n",
    "for index, (row, bitmap_array) in enumerate(zip(excel_data.iterrows(), segmentations)):\n",
    "    _, row = row  # Extract the row data\n",
    "    \n",
    "    # Calculate pixel counts from the bitmap\n",
    "    ribeye_pixels, fat_thickness_pixels = calculate_pixel_counts(bitmap_array)\n",
    "    \n",
    "    # Convert pixel counts to real-world measurements\n",
    "    area_sq_in, thickness_in = convert_pixels_to_measurements(ribeye_pixels, fat_thickness_pixels)\n",
    "    \n",
    "    # Update the DataFrame with the calculated measurements\n",
    "    excel_data.at[index, 'Calculated Ribeye Area (sq in)'] = area_sq_in\n",
    "    excel_data.at[index, 'Calculated Fat Thickness (in)'] = thickness_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e796bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-Processing - how can we change the image to seperate the fat + ribeye area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c13b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf4f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective -> Classify the beef images "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
